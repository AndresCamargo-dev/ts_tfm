---
title: "Scale ts"
author: "AndrÃ©s Camargo"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(lubridate)
library(Metrics)
library(zoo)
library(forecast)
library(prophet)
library(ggplot2)
library(deepANN)

s_ts = read.csv("data/sales_products_ts.csv")
```

```{r}
#get all ids of products
id_ts = unique(s_ts$id)

#delete unused column
s_ts = s_ts %>% select(c(id,date, quantity)) %>% mutate(date= ymd(date))

# define replace outliers function
replace_outliers <- function(x) {
  q3 = quantile(x$quantity, 0.75)
  q1 = quantile(x$quantity, 0.25)
  iqr = IQR(x$quantity, na.rm = TRUE)
  maxLimit = q3 + (1.5*iqr)
  minLimit = q1 - (1.5*iqr)
  
  x$quantity[x$quantity > maxLimit] <- maxLimit
  x$quantity[x$quantity < minLimit] <- minLimit
  
  return(x)
}

# RMSE function
rmse_na = function (x, y) {
  sqrt(mean((x - y)^2, na.rm = TRUE))
}
```

```{r}
#dataframes for saving results
models_predictions = data.frame(
  id = character(),
  date = as.Date(character(), format = "%Y-%m-%d"),
  quantity = numeric(),
  date_ym = character(),
  qtyLog = numeric(),
  qtyMean = numeric(),
  qtyLinear = numeric(),
  qtyRw = numeric(),
  qtyMA4 = numeric(),
  qtyArima =numeric(),
  qtyProphet =numeric(),
  stringsAsFactors = FALSE
)

models_performance = data.frame(
  id = character(),
  modelo = character(),
  rmse = numeric(),
  wape = numeric(),
  stringsAsFactors = FALSE
)

```

```{r}
i='00612001'
i='17410306'


```


```{r}

for (i in id_ts){
  #filter the dataset
  df = s_ts %>% filter(id== i) %>% 
      mutate(date_ym = paste(year(date), month(date), sep = "-")) %>% 
      arrange(date) %>% 
      distinct()
      
      # create chart of ts
      ts_plot = df %>% ggplot(aes(date, quantity)) + geom_line()
      ggsave(paste("scale_outputs/",i,"/images/ts_plot.png", sep=""), ts_plot)
      
      # Replace outliers
      df = replace_outliers(df)
      
      # Log transformation
      df['qtyLog'] = log(df$quantity+1)
      df %>% ggplot(aes(date, qtyLog)) + geom_line()
      
      # train/test split
      weeks_train = round(as.numeric(difftime(max(df$date), min(df$date), unit="weeks"))*0.7)
      split_date = min(df$date) + weeks(weeks_train)  
      #split_date = max(df$date) - weeks(4)
      train = df %>% filter(date< split_date)
      test = df %>% filter(date>=split_date)
      
      
      # mean model
      mean_model = mean(train$qtyLog)
      test['qtyMean'] = exp(mean_model)-1
        ## mean model evaluation
      models_performance <- rbind(models_performance, data.frame(
      id = i, 
      model = "mean", 
      rmse =  rmse_na(test$quantity,test$qtyMean),
      wape = wape(test$quantity,test$qtyMean)
      ))
        ## Plot
      mean_plot = test %>% ggplot(aes(date)) + 
      geom_line(aes(y = quantity, color = "actual")) +
      geom_line(aes(y = qtyMean, color = "Mean")) +
      labs(y = "Quantity", color = "Series")
      ggsave(paste("scale_outputs/",i,"/images/mean_plot.png", sep=""), mean_plot)
      
      
      # Linear model (time difference)
      train$timeIndex <- train$date - min(train$date)
        ## calculate time difference
      train$timeIndex <- interval(floor_date(min(train$date), unit = "week"), 
        floor_date(train$date, unit = "week")) / weeks(1)
      test$timeIndex <- interval(floor_date(min(test$date), unit = "week"), 
        floor_date(test$date, unit = "week")) / weeks(1)
        ## Prediction
      model_linear <- lm(qtyLog ~ timeIndex, data = train)
      model_linear_pred = predict(model_linear, test)
      test$qtyLinear = exp(model_linear_pred)-1
      models_performance <- rbind(models_performance, data.frame(
      id = i, 
      model = "linear", 
      rmse =  rmse_na(test$quantity,test$qtyLinear),
      wape = wape(test$quantity,test$qtyLinear)
      ))
        ## plot
      linear_plot = test %>% ggplot(aes(date)) + 
        geom_line(aes(y = quantity, color = "actual")) +
        geom_line(aes(y = qtyLinear, color = "linear")) +
        labs(y = "Quantity", color = "Series")
      ggsave(paste("scale_outputs/",i,"/images/linear_plot.png", sep=""), linear_plot)
      
      
      # Random Walk (t-1)
        ## create shift 1
      train$qtyLogShift1 = lag(train$qtyLog)
      rw_shift_plot = train %>% ggplot(aes(qtyLogShift1, qtyLog)) + geom_point()
      ggsave(paste("scale_outputs/",i,"/images/rw_shift_plot.png", sep=""), rw_shift_plot)
      train$qtyRandomW = exp(train$qtyLogShift1)-1
        ## Prediction
      test$qtyRw = tail(train$qtyRandomW, n=1)
      models_performance <- rbind(models_performance, data.frame(
      id = i, 
      model = "Random Walk", 
      rmse =  rmse_na(test$quantity,test$qtyRw),
      wape = wape(test$quantity,test$qtyRw)
      ))
        ## Plot
      rw_plot  = test %>% ggplot(aes(date)) + 
      geom_line(aes(y = quantity, color = "actual")) +
      geom_line(aes(y = qtyRw, color = "Random Walk")) +
      labs(y = "Quantity", color = "Series")
      ggsave(paste("scale_outputs/",i,"/images/rw_plot.png", sep=""), rw_plot)
      
   
      # Moving average
      window_size = 4
      qtyLogMA4 = rollmean(train$qtyLog, k=window_size, allign="right", fill=NA) 
      lastMA4 = tail(na.omit(qtyLogMA4), n=1)
        ## Prediction
      test$qtyMA4 = exp(lastMA4)-1
      models_performance <- rbind(models_performance, data.frame(
      id = i, 
      model = "Mooving Average", 
      rmse =  rmse_na(test$quantity,test$qtyMA4),
      wape = wape(test$quantity,test$qtyMA4)
      ))

        ## Plot
      ma4_plot  = test %>% ggplot(aes(date)) + 
      geom_line(aes(y = quantity, color = "actual")) +
      geom_line(aes(y = qtyMA4, color = "Moving Average")) +
      labs(y = "Quantity", color = "Series")
      ggsave(paste("scale_outputs/",i,"/images/ma4_plot.png", sep=""), ma4_plot)
      
      
      # Arima model
      ts_log = train$qtyLog
        ## model
      model_arima = auto.arima(ts_log)
      forecast_arima = forecast(model_arima, h=nrow(test))
      arima_plot = autoplot(forecast_arima)
      ggsave(paste("scale_outputs/",i,"/images/arima_plot.png", sep=""), arima_plot)
      forecast_arima_df = as.data.frame(forecast_arima[[4]])
      test$qtyArima = exp(forecast_arima_df$x)-1
        ## evaluation
      models_performance <- rbind(models_performance, data.frame(
      id = i, 
      model = "Arima", 
      rmse =  rmse_na(test$quantity,test$qtyArima),
      wape = wape(test$quantity,test$qtyArima)
      ))

      

      # Prophet model - baseline
        ## formating
      df_prophet = train %>% dplyr::select(c(date, qtyLog)) %>%
      rename(ds = date, y = qtyLog)
        ## model
      model_prophet = prophet(df_prophet)
      summary(model_prophet)
        ## predictions
      future_df = make_future_dataframe(model_prophet, periods=nrow(test), freq="week")
      forecast_prophet = predict(model_prophet, future_df)
        ## plot
      prophet_fcst_plot = plot(model_prophet, forecast_prophet)
      ggsave(paste("scale_outputs/",i,"/images/prophet_fcst_plot.png", sep=""), prophet_fcst_plot)
      prophet_components_plot = prophet_plot_components(
        model_prophet,forecast_prophet, uncertainty = TRUE, plot_cap = TRUE,
        weekly_start = 0, yearly_start = 0, render_plot = TRUE
      )
      for (j in seq_along(prophet_components_plot)){
        ggsave(paste("scale_outputs/",i,"/images/prophet_components_plot",j,".png", sep=""),
             prophet_components_plot[[j]])
      }
        ## evaluation
      qtyLogProphet = forecast_prophet$yhat[(nrow(train)+1):length(forecast_prophet$yhat)]
      test$qtyProphet = exp(qtyLogProphet)-1
      models_performance <- rbind(models_performance, data.frame(
      id = i, 
      model = "Prophet default Hyp", 
      rmse =  rmse_na(test$quantity,test$qtyProphet),
      wape = wape(test$quantity,test$qtyProphet)
      ))
        ## Plot prediction/actual
      plot_prophet_dft = test %>% ggplot(aes(date)) + 
      geom_line(aes(y = quantity, color = "Actual")) +
      geom_line(aes(y = qtyProphet, color = "Prophet")) +
      labs(y = "Quantity", color = "Series") + theme_minimal()
      ggsave(paste("scale_outputs/",i,"/images/prophet_dft_plot.png", sep=""), plot_prophet_dft)


      # Prophet - hyperparameters tunned
        ## data preparation
      df_prophet2 = df %>% dplyr::select(c(date, qtyLog)) %>%
      rename(ds = date, y = qtyLog)

        ## Fit the model
      auto_model <- prophet(df_prophet2, changepoint.prior.scale = best_params$changepoint_prior_scale, #0.05
                            seasonality.prior.scale = best_params$seasonality_prior_scale, #0.01
                            seasonality.mode = best_params$seasonality_mode) #multiplictive
      
        ## Cross-validation
      auto_model_cv <- cross_validation(auto_model, initial = round(as.numeric(difftime(split_date,  min(df$date), units = "days"))), period = 30, horizon = 30, units = 'days')
      auto_model_p <- performance_metrics(auto_model_cv, rolling_window = 1)
        ## Predictions
      fit_prophet = predict(auto_model)
      ph_test_predictions = fit_prophet %>% filter (ds >= split_date) 
      test$qtyProphetTun = exp(ph_test_predictions$yhat)-1
        ## save metrics
      models_performance <- rbind(models_performance, data.frame(
            id = i, 
            model = "Prophet HypOpt Cv", 
            rmse = rmse_na(test$quantity,test$qtyProphetTun),
            wape = wape(test$quantity,test$qtyProphetTun)
            #,smape = auto_model_p$smape[1]
            ))
        ## plot
      #plot(auto_model, fit_prophet)
      plot_prophet_tunned = test %>% ggplot(aes(date)) + 
      geom_line(aes(y = quantity, color = "Actual")) +
      geom_line(aes(y = qtyProphetTun, color = "Prophet Tunned")) +
      labs(y = "Quantity", color = "Series") + theme_minimal()
      ggsave(paste("scale_outputs/",i,"/images/prophet_tunned_plot.png", sep=""), plot_prophet_tunned)

      
      # Save files
      write.csv(test, paste("scale_outputs/",i,"/models_results.csv", sep=""))
      
      
      print(i)
      

}

write.csv(models_performance, paste("scale_outputs/all_models_performance.csv", sep=""))

```


Correct ARIMA

```{r}
# propuesta: reducir el periodo de test?
split_date = max(df$date) - weeks(8)  
train = df %>% filter(date< split_date)
test = df %>% filter(date>=split_date)



ts_log = train$qtyLog
model_arima = auto.arima(ts_log, stepwise = TRUE)
forecast_arima = forecast(model_arima, h=8)
#arima_plot = autoplot(forecast_arima)
#ggsave(paste("scale_outputs/",i,"/images/arima_plot.png", sep=""), arima_plot)
#forecast_arima_df = as.data.frame(forecast_arima[[4]])
test$qtyArima = exp(forecast_arima$mean)-1
  ## mean model evaluation
test['rmse_arima'] = rmse_na(test$quantity,test$qtyArima)
test['wape_arima'] = wape(test$quantity,test$qtyArima)


test %>% ggplot(aes(date)) + 
  geom_line(aes(y = quantity, color = "Actual")) +
  geom_line(aes(y = qtyArima, color = "Arima")) +
  labs(y = "Quantity", color = "Series")

nrow(test)

autoplot(forecast_arima, PI=FALSE)


```

Correct predictions dataset

```{r}
models_predictions = data.frame(
  id = character(),
  date = as.Date(character(), format = "%Y-%m-%d"),
  quantity = numeric(),
  date_ym = character(),
  qtyLog = numeric(),
  qtyMean = numeric(),
  qtyLinear = numeric(),
  qtyRw = numeric(),
  qtyMA4 = numeric(),
  qtyArima =numeric(),
  qtyProphet =numeric(),
  stringsAsFactors = FALSE
)

# replace empty values with NA
models_predictions[] <- lapply(models_predictions, function(x) ifelse(length(x) == 0, NA, x))

models_predictions <- rbind(models_predictions, data.frame(
    id = test$id,
    date = test$date,
    quantity = test$quantity,
    date_ym = test$date_ym,
    qtyLog = test$qtyLog,
    qtyMean = test$qtyMean,
    qtyLinear = test$qtyLinear,
    qtyRw = test$qtyRw,
    qtyMA4 = test$qtyMA4,
    qtyArima = test$qtyArima,
    qtyProphet = test$qtyProphet,
    stringsAsFactors = FALSE
      ))


test <- test %>% mutate(
  qtyMean = NA_real_,
  timeIndex = NA_real_,
  qtyLinear = NA_real_,
  qtyRw = NA_real_,
  qtyMA4 = NA_real_,
  qtyArima = NA_real_,
  qtyProphet= NA_real_,
  )


```

Create Prophet con Crossvalidation

```{r}

holidays = read.csv("data/festivos.csv")
holidays = holidays %>% filter(Lugar == "EspaÃ±a" | Lugar == "Madrid") %>% 
  mutate(
         holiday = festividad,
        ds = as.Date(fecha),
         lower_window= -2,
         upper_window = 2) %>% 
  select(!c(fecha, festividad, X, AÃ±o, Lugar, tipo)) 

events = data.frame(
      holiday = c("Covid", "blackfriday", "blackfriday", "blackfriday", "blackfriday"), 
      ds = c("2020-03-14", '2019-11-29','2020-11-27','2021-11-26', '2022-11-25'),
      lower_window = c(-15, -7, -7, -7,-7)  ,
      upper_window = c(15, 1,1,1,1)
      )

all_events <- rbind(events, holidays) 



# baseline prophet with crossvalidation
model_prophet2 = prophet(df_prophet2)
summary(model_prophet2)
  ## predictions
crossvalidation_prophet <- cross_validation(model_prophet2, initial = round(as.numeric(difftime(split_date, min(df$date), units = "days"))), period = 30, horizon = 30, units = 'days')
  ## performance metrics
pht2_metrics = performance_metrics(crossvalidation_prophet, rolling_window = 1)


# hyperparameters tunning
model_prophet3 = prophet(df_prophet2, yearly.seasonality = TRUE, changepoint.range = 0.9, holidays = events)
model_prophet3 = add_country_holidays(model_prophet3, country_name = 'SPA')
summary(model_prophet2)
  ## predictions
cv_prophet3 <- cross_validation(model_prophet3, initial = round(as.numeric(difftime(split_date, min(df$date), units = "days"))), period = 30, horizon = 30, units = 'days')
  ## performance metrics
performance_metrics(cv_prophet3, rolling_window = 1)


```

Hyperparameters Tunning with Grid Search

```{r}
## data preparation
df_prophet2 = df %>% dplyr::select(c(date, qtyLog)) %>%
rename(ds = date, y = qtyLog)

# Set up parameter grid
param_grid <- list(
  changepoint_prior_scale = c(0.001, 0.05, 0.08, 0.5),
  seasonality_prior_scale = c(0.01, 1, 5, 10, 12),
  seasonality_mode = c('additive', 'multiplicative')
)
# Generate all combinations of parameters
all_params <- expand.grid(param_grid)
# Create a list to store MAPE values for each combination
rmses <- numeric(length = nrow(all_params))
# Use cross validation to evaluate all parameters
for (k in seq_len(nrow(all_params))) {
  # Fit a model using one parameter combination
  params <- all_params[k, ]
  m <- prophet(
    df_prophet2,
    changepoint.prior.scale = params[["changepoint_prior_scale"]],
    seasonality.prior.scale = params[["seasonality_prior_scale"]],
    seasonality.mode = params[["seasonality_mode"]]
  )  
  # Cross-validation
  df_cv <- cross_validation(m, initial = round(as.numeric(difftime(split_date, min(df$date), units = "days"))), period = 30, horizon = 30, units = 'days')
  # Model performance
  df_p <- performance_metrics(df_cv, rolling_window=1)
  # Save model performance metrics
  rmses[k] <- df_p[['rmse']][1]
}

# Tuning results
tuning_results <- data.frame(all_params, rmse = rmses)
# Find the best parameters
best_params <- all_params[which.min(rmses), ]
print(best_params)

# Fit the model on the training dataset
auto_model <- prophet(df_prophet2, changepoint.prior.scale = best_params$changepoint_prior_scale, #0.05
                      seasonality.prior.scale = best_params$seasonality_prior_scale, #0.01
                      seasonality.mode = best_params$seasonality_mode) #multiplictive

# Cross-validation
initial_date = round(as.numeric(difftime(split_date-weeks(4),  min(df_prophet2$ds), units = "days")))
auto_model_cv <- cross_validation(auto_model, initial = initial_date, period = 30, horizon = 30, units = 'days')
auto_model_p <- performance_metrics(auto_model_cv, rolling_window = 1)
auto_model_p$rmse[1]


# Predictions
auto_model_cv_fil = auto_model_cv %>% filter(ds >= split_date)
test$qtyProphetTun = exp(auto_model_cv_fil$yhat)-1
# save metrics
models_performance <- rbind(models_performance, data.frame(
      id = i, 
      model = "Prophet HypOpt Cv", 
      rmse = rmse_na(test$quantity,test$qtyProphetTun),
      wape = wape(test$quantity,test$qtyProphetTun)
      #,smape = auto_model_p$smape[1]
      ))
# plot
plot(model_prophet, fit_prophet)
```



