---
title: "Scale_ts_clean"
author: "AndrÃ©s Camargo"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tidyverse)
library(lubridate)
library(Metrics)
library(zoo)
library(forecast)
library(prophet)
library(ggplot2)
library(deepANN)
library(foreach)


s_ts = read.csv("data/sales_products_ts.csv")
#s_ts = s_ts %>% filter(quantity !=0) ### PROVISIONAL
products_info = read.csv("data/products_statistics.csv")
```


```{r}
#get all ids of products
id_ts = unique(s_ts$id)

#delete unused column
s_ts = s_ts %>% select(c(id,date, quantity)) %>% mutate(date= ymd(date))

```

Defining functions

```{r}
# define replace outliers function
replace_outliers <- function(x) {
  q3 = quantile(x$quantity, 0.75)
  q1 = quantile(x$quantity, 0.25)
  iqr = IQR(x$quantity, na.rm = TRUE)
  maxLimit = q3 + (1.5*iqr)
  minLimit = q1 - (1.5*iqr)
  
  x$quantity[x$quantity > maxLimit] <- maxLimit
  x$quantity[x$quantity < minLimit] <- minLimit
  
  return(x)
}

# RMSE function
rmse_na = function (x, y) {
  sqrt(mean((x - y)^2, na.rm = TRUE))
}


# df for models errors
models_performance = data.frame(
  id = character(),
  modelo = character(),
  rmse = numeric(),
  wape = numeric(),
  mase = numeric(),
  stringsAsFactors = FALSE
)
```


ID for testing the code

```{r}
#i='17410306'
```

Multiple time series forecasting

```{r}

for (i in id_ts){
  #filter the dataset
  df = s_ts %>% filter(id== i) %>% 
      mutate(date_ym = paste(year(date), month(date), sep = "-")) %>% 
      arrange(date) %>% 
      distinct()
      
      # create chart of ts
      ts_plot = df %>% ggplot(aes(date, quantity)) + geom_line() 
      ggsave(paste("scale_outputs/",i,"/images/ts_plot.png", sep=""), ts_plot)
      
      
      facet_years = df %>% ggplot(aes(date, quantity)) +  geom_line() + facet_wrap(~ year(date), ncol = 3, scales = 'free_x')
      ggsave(paste("scale_outputs/",i,"/images/facet_years.png", sep=""), facet_years)
      
      # Replace outliers
      df = replace_outliers(df)
      
      # Log transformation
      df['qtyLog'] = log(df$quantity+1)
      df %>% ggplot(aes(date, qtyLog)) + geom_line()
      
      # train/test split
      weeks_train = round(as.numeric(difftime(max(df$date), min(df$date), unit="weeks"))*0.7)
      #split_date = min(df$date) + weeks(weeks_train)  
      split_date = max(df$date) - years(1)
      train = df %>% filter(date< split_date)
      test = df %>% filter(date>=split_date)
      
      
      # mean model
      mean_model = mean(train$qtyLog)
      test['qtyMean'] = exp(mean_model)-1
        ## mean model evaluation
      models_performance <- rbind(models_performance, data.frame(
      id = i, 
      model = "mean", 
      rmse =  rmse_na(test$quantity,test$qtyMean),
      wape = wape(test$quantity,test$qtyMean),
      mase = mase(test$quantity,test$qtyMean, step_size = 7)
      ))
        ## Plot
      mean_plot = test %>% ggplot(aes(date)) + 
      geom_line(aes(y = quantity, color = "actual")) +
      geom_line(aes(y = qtyMean, color = "Mean")) +
      labs(y = "Quantity", color = "Series")
      ggsave(paste("scale_outputs/",i,"/images/mean_plot.png", sep=""), mean_plot)
      
      
      # Linear model (time difference)
      train$timeIndex <- train$date - min(train$date)
        ## calculate time difference
      train$timeIndex <- interval(floor_date(min(train$date), unit = "week"), 
        floor_date(train$date, unit = "week")) / weeks(1)
      test$timeIndex <- interval(floor_date(min(test$date), unit = "week"), 
        floor_date(test$date, unit = "week")) / weeks(1)
        ## Prediction
      model_linear <- lm(qtyLog ~ timeIndex, data = train)
      model_linear_pred = predict(model_linear, test)
      test$qtyLinear = exp(model_linear_pred)-1
      models_performance <- rbind(models_performance, data.frame(
      id = i, 
      model = "linear", 
      rmse =  rmse_na(test$quantity,test$qtyLinear),
      wape = wape(test$quantity,test$qtyLinear),
      mase = mase(test$quantity,test$qtyLinear, step_size = 7)
      ))
        ## plot
      linear_plot = test %>% ggplot(aes(date)) + 
        geom_line(aes(y = quantity, color = "actual")) +
        geom_line(aes(y = qtyLinear, color = "linear")) +
        labs(y = "Quantity", color = "Series")
      ggsave(paste("scale_outputs/",i,"/images/linear_plot.png", sep=""), linear_plot)
      
      
      # Random Walk (t-1)
        ## create shift 1
      train$qtyLogShift1 = lag(train$qtyLog)
      rw_shift_plot = train %>% ggplot(aes(qtyLogShift1, qtyLog)) + geom_point()
      ggsave(paste("scale_outputs/",i,"/images/rw_shift_plot.png", sep=""), rw_shift_plot)
      train$qtyRandomW = exp(train$qtyLogShift1)-1
        ## Prediction
      test$qtyRw = tail(train$qtyRandomW, n=1)
      models_performance <- rbind(models_performance, data.frame(
      id = i, 
      model = "Random Walk", 
      rmse =  rmse_na(test$quantity,test$qtyRw),
      wape = wape(test$quantity,test$qtyRw),
      mase = mase(test$quantity,test$qtyRw, step_size = 7)
      ))
        ## Plot
      rw_plot  = test %>% ggplot(aes(date)) + 
      geom_line(aes(y = quantity, color = "actual")) +
      geom_line(aes(y = qtyRw, color = "Random Walk")) +
      labs(y = "Quantity", color = "Series")
      ggsave(paste("scale_outputs/",i,"/images/rw_plot.png", sep=""), rw_plot)
      
   
      # Moving average
      window_size = 4
      qtyLogMA4 = rollmean(train$qtyLog, k=window_size, allign="right", fill=NA) 
      lastMA4 = tail(na.omit(qtyLogMA4), n=1)
        ## Prediction
      test$qtyMA4 = exp(lastMA4)-1
      models_performance <- rbind(models_performance, data.frame(
      id = i, 
      model = "Mooving Average", 
      rmse =  rmse_na(test$quantity,test$qtyMA4),
      wape = wape(test$quantity,test$qtyMA4),
      mase = mase(test$quantity,test$qtyMA4, step_size = 7)
      ))

        ## Plot
      ma4_plot  = test %>% ggplot(aes(date)) + 
      geom_line(aes(y = quantity, color = "actual")) +
      geom_line(aes(y = qtyMA4, color = "Moving Average")) +
      labs(y = "Quantity", color = "Series")
      ggsave(paste("scale_outputs/",i,"/images/ma4_plot.png", sep=""), ma4_plot)
      
      
      # Arima model
      ts_log = train$qtyLog
        ## model
      model_arima = auto.arima(ts_log)
      forecast_arima = forecast(model_arima, h=nrow(test))
      arima_plot = autoplot(forecast_arima)
      ggsave(paste("scale_outputs/",i,"/images/arima_plot.png", sep=""), arima_plot)
      forecast_arima_df = as.data.frame(forecast_arima[[4]])
      test$qtyArima = exp(forecast_arima_df$x)-1
        ## evaluation
      models_performance <- rbind(models_performance, data.frame(
      id = i, 
      model = "Arima", 
      rmse =  rmse_na(test$quantity,test$qtyArima),
      wape = wape(test$quantity,test$qtyArima),
      mase = mase(test$quantity,test$qtyArima, step_size = 7)
      ))

      

      # Prophet model 
        
        ## Set up parallel backend
      n.cores = parallel::detectCores() -1
      my.cluster = parallel::makeCluster(
        n.cores,
        type= "PSOCK"
      )
      doParallel::registerDoParallel(cl = my.cluster)
      foreach::getDoParRegistered()
      
        ## Data preparation
      df_prophet2 = df %>% dplyr::select(c(date, qtyLog)) %>%
      rename(ds = date, y = qtyLog)
      
        ## Set up parameter grid
      param_grid <- list(
        changepoint_prior_scale = c(0.001, 0.05, 0.08, 0.5),
        seasonality_prior_scale = c(0.01, 1, 5, 10, 12),
        seasonality_mode = c('additive', 'multiplicative')
      )
      
        ## Generate all combinations of parameters
      all_params <- expand.grid(param_grid)
      
        ## Create a list to store RMSE values for each combination
      rmses <- foreach(k = 1:nrow(all_params), .combine = 'c', .packages = 'prophet') %dopar% {
        # Fit a model using one parameter combination
        params <- all_params[k, ]
        m <- prophet(
          df_prophet2,
          changepoint.prior.scale = params[["changepoint_prior_scale"]],
          seasonality.prior.scale = params[["seasonality_prior_scale"]],
          seasonality.mode = params[["seasonality_mode"]]
        )
        # Cross-validation
        df_cv <- cross_validation(m, initial = round(as.numeric(difftime(split_date, min(df$date), units = "days"))), period = 30, horizon = 30, units = 'days')
        # Model performance
        df_p <- performance_metrics(df_cv, rolling_window = 1)
        # Return RMSE value
        df_p[['rmse']][1]
      }
      
        # Stop the parallel backend
      parallel::stopCluster(cl = my.cluster)
      
        # Combine parameter grid and RMSE values
      tuning_results <- data.frame(all_params, rmse = rmses)
      
        # Find the best parameters
      best_params <- all_params[which.min(rmses), ]
      write.csv(best_params, paste("scale_outputs/",i,"/best_params.csv", sep=""))
        ## Fit the model
      auto_model <- prophet(df_prophet2, changepoint.prior.scale = best_params$changepoint_prior_scale, 
                            seasonality.prior.scale = best_params$seasonality_prior_scale, 
                            seasonality.mode = best_params$seasonality_mode) 
      
        ## Cross-validation
      auto_model_cv <- cross_validation(auto_model, initial = round(as.numeric(difftime(split_date,  min(df$date), units = "days"))), period = 30, horizon = 30, units = 'days')
      auto_model_p <- performance_metrics(auto_model_cv, rolling_window = 1)
        ## Predictions
      fit_prophet = predict(auto_model)
      ph_test_predictions = fit_prophet %>% filter (ds >= split_date) 
      test$qtyProphetTun = exp(ph_test_predictions$yhat)-1
        ## save metrics
      models_performance <- rbind(models_performance, data.frame(
            id = i, 
            model = "Prophet HypOpt Cv", 
            rmse = rmse_na(test$quantity,test$qtyProphetTun),
            wape = wape(test$quantity,test$qtyProphetTun),
            mase = mase(test$quantity,test$qtyProphetTun, step_size = 7)
            #,smape = auto_model_p$smape[1]
            ))
        ## plot
      #plot(auto_model, fit_prophet)
      plot_prophet_tunned = test %>% ggplot(aes(date)) + 
      geom_line(aes(y = quantity, color = "Actual")) +
      geom_line(aes(y = qtyProphetTun, color = "Prophet Tunned")) +
      labs(y = "Quantity", color = "Series") + theme_minimal()
      ggsave(paste("scale_outputs/",i,"/images/prophet_tunned_plot.png", sep=""), plot_prophet_tunned)
      
      
      
      # Save files
      write.csv(test, paste("scale_outputs/",i,"/models_results.csv", sep=""))
      
      
      print(i)
      

}

# Include products statistics
models_performance = models_performance %>% left_join(products_info, by='id') %>%  
  select(id,model,rmse,wape,num_records, percentage_zero, n_zero, n_wk_consecutive) 

write.csv(models_performance, paste("scale_outputs/all_models_performance.csv", sep=""))

```

