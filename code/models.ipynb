{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from statsmodels.tsa.stattools import acovf\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from prophet import Prophet\n",
    "import itertools\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from prophet.plot import plot_plotly\n",
    "import xgboost as xgb\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sktime.performance_metrics.forecasting import MeanAbsoluteScaledError\n",
    "from pmdarima.arima import auto_arima\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('../data/sales_products_ts.csv')\n",
    "products_info = pd.read_csv(\"../data/products_statistics.csv\")\n",
    "holidays = pd.read_csv('../data/festivos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sales = pd.read_csv('../data/historico_ventas.csv')\n",
    "# sales = sales[sales['material'].isin(products_info['id'])]\n",
    "# sales.rename(columns={'material':'id', 'fecha_semana':'date', 'cantidad':'quantity'}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define error functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return mean_absolute_percentage_error(y_true, y_pred)\n",
    "\n",
    "def wape(y_true, y_pred):\n",
    "    acovf_vals = acovf(y_true, unbiased=False)\n",
    "    return np.sum(np.abs(y_true - y_pred) / acovf_vals) * 100\n",
    "\n",
    "# metric for interminent demand series\n",
    "mase = MeanAbsoluteScaledError()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define metrics dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(columns=['id','model','rmse', 'mape', 'mase'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace outliers function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outliers(df):\n",
    "    q3 = np.quantile(df['quantity'], 0.75)\n",
    "    q1 = np.quantile(df['quantity'], 0.25)\n",
    "    iqr = np.subtract(*np.percentile(df['quantity'], [75, 25], interpolation='linear', axis=0))\n",
    "    max_limit = q3 + (1.5 * iqr)\n",
    "    min_limit = q1 - (1.5 * iqr)\n",
    "    df.loc[df['quantity'] > max_limit, 'quantity'] = max_limit\n",
    "    df.loc[df['quantity'] < min_limit, 'quantity'] = min_limit\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    sorted = df.groupby('id').sum('quantity').sort_values('quantity', ascending=False)\n",
    "    id_list = sorted.index.unique()\n",
    "    df['date'] = pd.DatetimeIndex(df.date)\n",
    "    df = df.sort_values('date')\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.index = pd.PeriodIndex(df.date, freq='W')\n",
    "    df['log'] = np.log1p(df.quantity)\n",
    "    df = df[['id','date', 'quantity', 'log']]\n",
    "    return df, id_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_plots(df, item):\n",
    "    fig, (a1,a2) = plt.subplots(1,2, figsize=(15, 5))\n",
    "    a1.plot(df.date, df['quantity'])\n",
    "    a1.set_title(f'Original Serie - {item}')\n",
    "    a2.plot(df.date, df['log'], color='r')\n",
    "    a2.set_title(f'Log Transformation - {item}')\n",
    "    fig.tight_layout()\n",
    "    os.makedirs(f'../scale_outputs/{item}/images/', exist_ok=True)\n",
    "    fig.savefig(f'../scale_outputs/{item}/images/ts_plot.png')\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df):\n",
    "  weeks_train = round((max(df['date']) - min(df['date'])).days / 7 * 0.8)\n",
    "  split_date = min(df['date']) + timedelta(weeks=weeks_train)\n",
    "  train = df[df['date']< split_date] \n",
    "  test = df[df['date'] >= split_date]\n",
    "  return split_date, train, test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mean_model(df, train, test, item):\n",
    "    mean_model = train.log.mean()\n",
    "    test['qtyMean'] = np.expm1(mean_model)\n",
    "    df = df.merge(test[['qtyMean']], how= 'left', left_index=True, right_index=True)\n",
    "    plot = df.plot(kind=\"line\", x=\"date\", y = [\"quantity\", 'qtyMean'])\n",
    "    os.makedirs(f'../scale_outputs/{item}/images/', exist_ok=True)\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig(f'../scale_outputs/{item}/images/mean_model.png')\n",
    "    row = {'id': item, \n",
    "         'model': 'mean', \n",
    "         'rmse': round(rmse(test.quantity,test.qtyMean)),  \n",
    "         'mape': round(mape(test.quantity,test.qtyMean),2),  \n",
    "         'mase': round(mase(test.quantity,test.qtyMean, y_train=train.quantity, sp=7),2)\n",
    "         }\n",
    "    global metrics\n",
    "    metrics = pd.concat([metrics, pd.DataFrame(row, index=[0])], ignore_index=True)\n",
    "\n",
    "    return df, test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear model\n",
    "* Time difference "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_linear_model(df, train, test, item):\n",
    "    train['timeIndex'] = train.date - train.date.min()\n",
    "    train[\"timeIndex\"] =  train[\"timeIndex\"]/np.timedelta64(1, 'W')\n",
    "    train[\"timeIndex\"] = train[\"timeIndex\"].round(0).astype(int)\n",
    "    test['timeIndex'] = test.date - train.date.min() # verificar si se compara contra el date de train o test\n",
    "    test[\"timeIndex\"] =  test[\"timeIndex\"]/np.timedelta64(1, 'W')\n",
    "    test[\"timeIndex\"] = test[\"timeIndex\"].round(0).astype(int)\n",
    "    model = smf.ols('log ~ timeIndex', data = train).fit()\n",
    "    model_linear_pred = model.predict(test)\n",
    "    test['qtyLinear'] = np.expm1(model_linear_pred)\n",
    "    df = df.merge(test[['qtyLinear','timeIndex']], how= 'left', left_index=True, right_index=True)\n",
    "    #plot = df.plot(kind=\"line\", x=\"timeIndex\", y = \"qtyLinear\")\n",
    "    #plt.plot(df.timeIndex,model_linear_pred, '-')\n",
    "#     os.makedirs(f'../scale_outputs/{item}/images/', exist_ok=True)\n",
    "#     fig = plot.get_figure()\n",
    "#     fig.savefig(f'../scale_outputs/{item}/images/linear_model.png')\n",
    "    row = {'id': item, \n",
    "         'model': 'Linear model', \n",
    "         'rmse': round(rmse(test.quantity,test.qtyLinear)),  \n",
    "         'mape': round(mape(test.quantity,test.qtyLinear),2),  \n",
    "         'mase': round(mase(test.quantity,test.qtyLinear, y_train=train.quantity, sp=7),2)\n",
    "         }\n",
    "    global metrics\n",
    "    metrics = pd.concat([metrics, pd.DataFrame(row, index=[0])], ignore_index=True)\n",
    "\n",
    "    return df, train, test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_random_walk(df, train, test, item):\n",
    "    train['lag'] = train.quantity.shift()\n",
    "    #train.plot(kind= \"scatter\", y = \"log\", x = \"lag_log\", s = 50);\n",
    "    test['qtyRW'] = train.lag.tail(n=1).values[0]\n",
    "    df = df.merge(test[['qtyRW']], how= 'left', left_index=True, right_index=True)\n",
    "    plot = df.plot(kind=\"line\", x=\"date\", y = [\"quantity\", 'qtyRW'])\n",
    "    os.makedirs(f'../scale_outputs/{item}/images/', exist_ok=True)\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig(f'../scale_outputs/{item}/images/random_walk_model.png')\n",
    "    row = {'id': item, \n",
    "         'model': 'Random Walk', \n",
    "         'rmse': round(rmse(test.quantity,test.qtyRW)),  \n",
    "         'mape': round(mape(test.quantity,test.qtyRW),2),  \n",
    "         'mase': round(mase(test.quantity,test.qtyRW, y_train=train.quantity, sp=7),2)\n",
    "         }\n",
    "    global metrics\n",
    "    metrics = pd.concat([metrics, pd.DataFrame(row, index=[0])], ignore_index=True)\n",
    "\n",
    "    return df, train, test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_moving_average(df, train, test, item):\n",
    "    train['log_MA4'] = df.log.rolling(window = 4).mean()\n",
    "    test['qtyMA4'] = np.expm1(train.log_MA4.tail(n=1).values[0])\n",
    "    df = df.merge(test[['qtyMA4']], how= 'left', left_index=True, right_index=True)\n",
    "#     plot = df.plot(kind=\"line\", x=\"date\", y = [\"quantity\", 'qtyMA4'])\n",
    "#     fig = plot.get_figure()\n",
    "#     fig.savefig(f'../scale_outputs/{item}/images/moving_average.png')\n",
    "    row = {'id': item, \n",
    "         'model': 'Moving average', \n",
    "         'rmse': round(rmse(test.quantity,test.qtyMA4)),  \n",
    "         'mape': round(mape(test.quantity,test.qtyMA4),2),  \n",
    "         'mase': round(mase(test.quantity,test.qtyMA4, y_train=train.quantity, sp=7),2)\n",
    "         }\n",
    "    global metrics\n",
    "    metrics = pd.concat([metrics, pd.DataFrame(row, index=[0])], ignore_index=True)\n",
    "\n",
    "    return df, train, test\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_arima(df, train, test, item):\n",
    "    ts_log = train.log\n",
    "    model = auto_arima(ts_log,start_p=0, d=1, start_q=0, \n",
    "                          max_p=5, max_d=5, max_q=5, start_P=0, \n",
    "                          D=1, start_Q=0, max_P=5, max_D=5,\n",
    "                          max_Q=5, m=12, seasonal=True, \n",
    "                          error_action='warn',trace = True,\n",
    "                          supress_warnings=True,stepwise = True,\n",
    "                          random_state=20,n_fits = 50 )\n",
    "    test['qtyArima'] = np.expm1(model.predict(n_periods =len(df.index)))\n",
    "    df = df.merge(test[['qtyArima']], how= 'left', left_index=True, right_index=True)\n",
    "    plot = df.plot(kind=\"line\", x=\"date\", y = [\"quantity\", 'qtyArima'])\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig(f'../scale_outputs/{item}/images/arima.png')\n",
    "    row = {'id': item, \n",
    "         'model': 'Arima', \n",
    "         'rmse': round(rmse(test.quantity,test.qtyArima)),  \n",
    "         'mape': round(mape(test.quantity,test.qtyArima),2),  \n",
    "         'mase': round(mase(test.quantity,test.qtyArima, y_train=train.quantity, sp=7),2)\n",
    "         }\n",
    "    global metrics\n",
    "    metrics = pd.concat([metrics, pd.DataFrame(row, index=[0])], ignore_index=True)\n",
    "\n",
    "    return df, test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prophet\n",
    "\n",
    "$Y_t = g(t) + s(t) + h(t) + e_t$\n",
    "\n",
    "* $g(t)$ growth term\n",
    "* $s(t)$: seasonal patterns\n",
    "* $h(t)$: holidays effects\n",
    "* $e_t$: error term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_hyperparameters_prophet(df, train, test, item, split_date):\n",
    "    new_df = pd.DataFrame({'ds': df.index.to_timestamp(),'y':df.log}).reset_index()\n",
    "    new_df = new_df.drop('date', axis=1)\n",
    "    param_grid = {  \n",
    "        'changepoint_prior_scale': [0.001, 0.01, 0.1, 0.5],\n",
    "        'seasonality_prior_scale': [0.01, 0.1, 1.0, 10.0],\n",
    "        'seasonality_mode': ['additive', 'multiplicative']\n",
    "    }\n",
    "\n",
    "    # Generate all combinations of parameters\n",
    "    all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "    rmses = []  # Store the RMSEs for each params here\n",
    "\n",
    "    # Use cross validation to evaluate all parameters\n",
    "    for params in all_params:\n",
    "        m = Prophet(**params, growth='flat') # flat is used to avoid errors\n",
    "        m.add_country_holidays(country_name='ES')\n",
    "        m.fit(new_df) \n",
    "        df_cv = cross_validation(m, initial='500 days', period='30 days', horizon='30 days', parallel=\"processes\")\n",
    "        df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "        rmses.append(df_p['rmse'].values[0])\n",
    "        \n",
    "    # Find the best parameters\n",
    "    tuning_results = pd.DataFrame(all_params)\n",
    "    tuning_results['rmse'] = rmses\n",
    "    #print(tuning_results)\n",
    "\n",
    "    # Find the best parameters\n",
    "    best_params = all_params[np.argmin(rmses)]\n",
    "    return new_df, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_prophet(df, p_df, best_params, train, test, item, split_date):\n",
    "    auto_model = Prophet(changepoint_prior_scale=best_params['changepoint_prior_scale'], \n",
    "                        seasonality_prior_scale=best_params['seasonality_prior_scale'], \n",
    "                        seasonality_mode=best_params['seasonality_mode'], growth='flat')\n",
    "    # Add holidays\n",
    "    auto_model.add_country_holidays(country_name='ES')\n",
    "    # Fit the model\n",
    "    auto_model.fit(p_df)\n",
    "    # Cross validation\n",
    "    days = (split_date - p_df.ds.min()).days\n",
    "    days = str(days-30) + \" days\" # we substract 30 days to ensure test date period\n",
    "    auto_model_cv = cross_validation(auto_model, initial=days, period='30 days', horizon = '30 days', parallel=\"processes\")\n",
    "    # Model performance metrics\n",
    "    auto_model_cv_p = performance_metrics(auto_model_cv, rolling_window=1)\n",
    "    # save results for test split (exponential transformation)\n",
    "    auto_model_cv_test = auto_model_cv[auto_model_cv['ds'] >= split_date]\n",
    "    auto_model_cv_test.index = pd.PeriodIndex(auto_model_cv_test.ds, freq='W')\n",
    "    test['qtyProphet'] = np.expm1(auto_model_cv_test.yhat)\n",
    "    df = df.merge(test[['qtyProphet']], how= 'left', left_index=True, right_index=True)\n",
    "    plot = df.plot(kind=\"line\", x=\"date\", y = [\"quantity\", 'qtyProphet'])\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig(f'../scale_outputs/{item}/images/prophet.png')\n",
    "    # save metrics\n",
    "    row = {'id': item, \n",
    "         'model': 'Prophet', \n",
    "         'rmse': round(rmse(test.quantity,test.qtyProphet)),  \n",
    "         'mape': round(mape(test.quantity,test.qtyProphet),2),  \n",
    "         # revisar si se utiliza el df cv para el MASE\n",
    "         'mase': round(mase(test.quantity,test.qtyProphet, y_train=train.quantity, sp=7),2) \n",
    "         }\n",
    "\n",
    "    global metrics\n",
    "    metrics = pd.concat([metrics, pd.DataFrame(row, index=[0])], ignore_index=True)\n",
    "    \n",
    "    return df, test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_initial_transformations(df):\n",
    "    df = df.set_index('date')\n",
    "    df.index = pd.to_datetime(df.index).normalize()\n",
    "    df = df.sort_index()\n",
    "    df['week'] = df.index.week\n",
    "    df['mes'] = df.index.month\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation Ilustration:\n",
    "* 5 Folds, test size of 1 quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_xgb_split_cv(df):\n",
    "    split_cv = TimeSeriesSplit(n_splits=5, test_size=4*3*1, gap=7) \n",
    "    fig, axs = plt.subplots(5, 1, figsize=(15, 15), sharex=True)\n",
    "    fold = 0\n",
    "    for train_idx, val_idx in split_cv.split(df):\n",
    "        train = df.iloc[train_idx]\n",
    "        test = df.iloc[val_idx]\n",
    "        train['quantity'].plot(ax=axs[fold],\n",
    "                            label='Training Set',\n",
    "                            title=f'Data Train/Test Split Fold {fold}')\n",
    "        test['quantity'].plot(ax=axs[fold],\n",
    "                            label='Test Set')\n",
    "        axs[fold].axvline(test.index.min(), color='black', ls='--')\n",
    "        fold += 1\n",
    "    \n",
    "    return fig, split_cv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Lag variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_xgb_create_lag(df):\n",
    "    target_map = df['quantity'].to_dict()\n",
    "    df['lag_year'] = (df.index - pd.Timedelta('364 days')).map(target_map)\n",
    "    df[['quantity', 'lag_year']].tail()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_xgb_cv_tuning(df, split_cv, item):\n",
    "        fold= 0\n",
    "        predictions_cv = []\n",
    "        mape_scores_cv = [] \n",
    "        rmse_scores_cv = [] \n",
    "        mase_scores_cv = []\n",
    "        for train_idx, val_idx in split_cv.split(df):\n",
    "                train = df.iloc[train_idx]\n",
    "                test = df.iloc[val_idx]\n",
    "                \n",
    "                FEATURES = ['mes','week', 'lag_year'] # add holidays\n",
    "                TARGET = ['quantity']\n",
    "\n",
    "                x_train = train[FEATURES]\n",
    "                y_train = train[TARGET]\n",
    "\n",
    "                x_test = test[FEATURES]\n",
    "                y_test = test[TARGET]\n",
    "\n",
    "                reg = xgb.XGBRegressor(base_score=0.5, booster='gbtree',    \n",
    "                                        n_estimators=1000,\n",
    "                                        early_stopping_rounds=50,\n",
    "                                        objective='reg:linear',\n",
    "                                        max_depth=3,\n",
    "                                        learning_rate=0.01)\n",
    "                reg.fit(x_train, y_train,\n",
    "                        eval_set=[(x_train, y_train), (x_test, y_test)],\n",
    "                        verbose=100)\n",
    "\n",
    "                y_pred = reg.predict(x_test)\n",
    "                predictions_cv.append(y_pred)\n",
    "                #score =  # RMSE formula\n",
    "                mape_score = mape(y_test, y_pred)\n",
    "                mape_scores_cv.append(mape_score)\n",
    "                rmse_score = rmse(y_test, y_pred)\n",
    "                rmse_scores_cv.append(rmse_score)\n",
    "                mase_score = mase(y_test,y_pred, y_train=y_train, sp=7)\n",
    "                mase_scores_cv.append(mase_score)\n",
    "        row = {'id': item, \n",
    "         'model': 'XGBoost', \n",
    "         'rmse': round(np.mean(rmse_scores_cv)),  \n",
    "         'mape': round(np.mean(mape_scores_cv),2),  \n",
    "         'mase': round(np.mean(mase_scores_cv),2)\n",
    "         }\n",
    "        global metrics\n",
    "        metrics = pd.concat([metrics, pd.DataFrame(row, index=[0])], ignore_index=True)\n",
    "\n",
    "        return predictions_cv, rmse_scores_cv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_xgb_fitmodel(df):\n",
    "    FEATURES = ['mes','week', 'lag_year'] \n",
    "    TARGET = ['quantity']\n",
    "\n",
    "    x_all = df[FEATURES]\n",
    "    y_all = df[TARGET]\n",
    "\n",
    "    reg = xgb.XGBRegressor(base_score=0.5,\n",
    "                        booster='gbtree',    \n",
    "                        n_estimators=500, # avoid overfitting\n",
    "                        objective='reg:linear',\n",
    "                        max_depth=3,\n",
    "                        learning_rate=0.01)\n",
    "    adv_xgb_model = reg.fit(x_all, y_all,\n",
    "            eval_set=[(x_all, y_all)],\n",
    "            verbose=100)\n",
    "    \n",
    "    return adv_xgb_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_future_importance(model):\n",
    "    fi = pd.DataFrame(data= model.feature_importances_,\n",
    "                    index=model.feature_names_in_,\n",
    "                    columns=['importance'])\n",
    "    plot_fi = fi.sort_values('importance').plot(kind='barh', title='Feature Importance')\n",
    "    return plot_fi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to appy XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_adv_xgb(df):\n",
    "    #df = df[df[variable] != 0]\n",
    "    df = xgb_initial_transformations(df)\n",
    "    plot_crossvalidation, split_cv = adv_xgb_split_cv(df)\n",
    "    df = adv_xgb_create_lag(df)\n",
    "    predictions_cv, scores_cv = adv_xgb_cv_tuning(df, split_cv, item)\n",
    "    model = adv_xgb_fitmodel(df)\n",
    "    plot_future_importance = xgb_future_importance(model)\n",
    "    # # plot_test_evaluation = xgb_evaluation(df, test, model, predictors_test)\n",
    "    # df_forecast, forecasting_plot = adv_xgb_forecasting(15, df, model)\n",
    "    # return forecasting_plot\n",
    "    #return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = sales[sales['quantity']!=0]\n",
    "sales, id_list = preprocessing(sales)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple time series loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in id_list:\n",
    "    one_product = sales[sales['id']==item]\n",
    "    one_product = one_product.drop_duplicates()\n",
    "    one_product = replace_outliers(one_product)\n",
    "    ts_plot = initial_plots(one_product, item)\n",
    "    split_date, train, test = split(one_product)\n",
    "    one_product, test = apply_mean_model(one_product, train, test, item)\n",
    "    one_product, train, test = apply_linear_model(one_product, train, test, item)\n",
    "    one_product, train, test = apply_random_walk(one_product, train, test, item)\n",
    "    one_product, train, test = apply_moving_average(one_product, train, test, item)\n",
    "    apply_adv_xgb(one_product)\n",
    "    #one_product, test = apply_arima(one_product, train, test, item)\n",
    "    #prophet_product, best_params = tuning_hyperparameters_prophet(one_product, train, test, item, split_date)\n",
    "    #one_product, test = apply_prophet(one_product, prophet_product, best_params, train, test, item, split_date)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include complementary info about products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = metrics.merge(products_info[['id','num_records', 'percentage_zero','n_zero', 'n_wk_consecutive']], how='left', on='id')\n",
    "\n",
    "metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_ex = '17410306'\n",
    "m = sales[sales['id']== id_ex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
